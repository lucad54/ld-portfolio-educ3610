---
title: Intellectual Productions
layout: about
permalink: /production3.html
# include CollectionBuilder info at bottom
credits: false
# Edit the markdown on in this file to describe your collection
# Look in _includes/feature for options to easily add features to the page
---

{% include feature/jumbotron.html objectid="background01" %}

{% include feature/nav-menu.html sections="Production 3 - GenAI Essay;References" %}

## Production 3 - GenAI Essay

### Intro 
For this production, I selected to use OpenAI's ChatGPT as it is on of the AI models "at the forefront of promoting AI as a solution to some of the biggest challenges in education" (Birhan, 2025, p. 54). As my teachable history, I started my probe into AI with the prompt “simulate (role play) a person or historical actor from the past and engage in dialogue about a specific historical event/situation or controversy,” following the example direction from Production 3. More specifically, I prompted ChatGPT to role-play Julius Caesar in a dialogue about his assassination in 44 BCE. My purpose was not to see whether the AI could “create” a text on/by a historical figure, but to see how accurate and/or harmful its output was in relation to history education. My hope for this production is to reveal both the potential and dangers of AI in history education, exposing its biases and inaccuracies as a historical source.

{% include feature/image.html objectid="chat01" %}

### My Contact
After the first prompt, I quickly saw its historical inaccuracies, insinuating that Caesar knew what was going to happen to him on the “Ides of March”. The response was light-hearted, it was in English and was almost childishly asking if we “would have me heed these omens, or stride forth as Rome’s destined ruler?” as if we had a say in the past history. My next step was to push the AI to fix these loose generalizations and cliches, prompting it to “speak the language of the time and not act as if Caesar knew what was going to happen, no childish play either”. The AI basically ignored my prompt, even after assuring that it “understood” my requests as seen below). 

{% include feature/image.html objectid="chat02" %}

I then more specifically prompted, “speak Latin, and ignore the 'audience’, roleplaying with the senate”. This finally fixed the algorithmic bias of ChatGPT of speaking English; however, I now faced the problem of not understanding Latin, so I went back and fixed my prompt to “speak Latin, and ignore the 'audience’, roleplaying with the senate (with English translations after)”. This worked, and the AI seemed to be using historical quotes from the senate before Caesar's assassination, so I simply asked the AI where it was getting information from. ChatGPT quickly defends its “work” by saying it's not ancient text but a “historical simulation”. It follows itself, stating a number of “primary sources” as seen above.

{% include feature/image.html objectid="chat04" %}

### Learning Potential
Through this production, I learned that with proper and strict guidelines, ChatGPT could produce somewhat “historical” texts, but it is prone to "hallucination”. For example, when I asked where its bold Latin speeches came from, it admitted they were not translations of ancient texts but “historical simulations” with primary sources from that period. Pulling methods from sources like Suetonius and Cicero, a historical writer and a contemporary, respectively. This honesty is useful, but it also exposes the risk that students and/or teachers might mistake these reconstructions for primary sources if they are not critically examining the AI. I found this connected to Thumlert et al.’s discussion of “algorithmic world-making, explaining how algorithms do not simply provide neutral information but co-produce with users a mediated version of reality (Thumlert et al., 2023, p. 23). In my experience with AI, it was not going into Caesar's or other contemporaries’ words but generating a version of him that was based on its training data. Altogether, this exprienment began to reveal the creative and dangerous potential AI holds in a history classroom. 

{% include feature/image.html objectid="chat03" %}

### Algorithmic Bias and Assumptions
As stated before, ChatGPT’s outputs quickly revealed biases shaped by its programming and dataset. When I asked to talk as a Roman leader, it did not speak Latin but instead its first instinct was to create an almost Shakespearean English response. This can be connected to how the AI's literary data got lazy around the 1500s, relying on Renaissance literary representations of Caesar (especially “Julius Caesar” by Shakespear) to create a historical figure. Only after repeated and specific corrections did it attempt Latin, which must be less represented in its dataset. Connecting again to Thumlert et al.'s argument, algorithms reflect “the goals, biases, prejudices, and values of their programmers” and training data (Thumlert et al., 2023, p. 20).

### Risks for Education
Many students and teachers have turned to AI for “help” on a number of subjects and in education. If they begin relying on ChatGPT for historical reconstructions instead of working with primary sources, oral and written histories, and classrooms, learners become “used to dependence on others [human or non-human] to make decisions for them” (Thumlert et al., 2023, p. 26). This AI-generated text tries to mimic primary sources to seem “authentic” and could easily be mistaken for them by a younger student. If a student believes the words of AI and submits a paper with evidence based on an AI-historical figure, they have created an accidental fabrication of history. My interaction with ChatGPT displays this risk, rather than parsing Caesar’s Commentarii or Cicero’s speeches as its “own” words to push the story it created.

Production 3 taught me that prompt literacy would be a necessary skill in order to even think of using AI models like ChatGPT. By tightening my prompts, I began to steer the AI away from clichés and dramatizations toward a somewhat historical reconstruction. Highlighting how AI requires existing expertise to use, without my historical background, I might not have fought with the AI so much about its inaccuracies. The screenshots throughout my text display this progression, from dramatic, English-only responses filled with foreshadowing to more scholarly-based, Latin speeches with translations. As "vendors market generative AI as a powerful technology with the capacity to solve a multitude of societal, structural, political and economic challenges" this expriement shows how Ai algorithms push their own ideas of entertainment and simplicity onto its users, unless used with precise prompts (Birhan, 2025, p. 53).

### Conclusion
This activity showed me ChatGPT’s strengths and weaknesses. With strict prompting, it can generate creative reconstructions, language practice, or entertaining engagement with the past. Yet, its biases and reliance on cultural tropes, its algorithmic assumptions, and its tendency to hallucinate the truth are all risks for proper education. Historical educators, if they must, should accept AI as a tool for critical inquiry rather than as a source of historical truth. Following Thumlert et al., we must understand not only what the AI produces but also why and how it produces it (Thumlert et al., 2023, p. 24–26). I feel that an activity like this one, where one compares AI-generated content and real historical evidence, is a great way to warn students and teachers alike of the risks of AI. Used critically, it can spark curiosity and reflection. Used uncritically, it risks simplifying history into cliché. Overall, my experiment with ChatGPT reveals the falsehood behind bringing historical figures back to life; it is more a mirror of our own culture narrative mixed with the algorithmic world-making and biases fed to AI.


## References

Birhan, A. (2025) The incomputable classroom: The limits and dangers of AI in education. In, *AI and the future of education.* Unesco. (Page 52). 

Thumlert, K., McBride, M., Tomin, B., Nolan, J., Lotherington, H., & Boreland, T. (2023). Algorithmic literacies: Identifying educational models and heuristics for engaging the challenge of algorithmic culture. *Digital Culture and Education.*

OpenAI. (2025). *ChatGPT* (Sept 22 version) [Large language model]. [https://chat.openai.com/](https://chat.openai.com/)
